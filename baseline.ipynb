{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "199be930-7e11-43f4-b056-a52fc1a93dc8",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dfa2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.prerequisite import install_requirements, download_data\n",
    "install_requirements()\n",
    "download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94dc6b5c-f92a-403d-a6f0-599f712dd15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3574acd8-517e-4fd2-ae11-cbe2e3b10d33",
   "metadata": {},
   "source": [
    "## Load Train / Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa791ae7-c9bb-4bcb-9228-41acbb9acecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code1_path</th>\n",
       "      <th>code2_path</th>\n",
       "      <th>code1</th>\n",
       "      <th>code2</th>\n",
       "      <th>similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./train_code/problem393/problem393_19.cpp</td>\n",
       "      <td>./train_code/problem033/problem033_439.cpp</td>\n",
       "      <td>#include &lt;bits/stdc++.h&gt;\\n\\nusing namespace st...</td>\n",
       "      <td>#include &lt;algorithm&gt;\\n#include &lt;bitset&gt;\\n#incl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./train_code/problem019/problem019_210.cpp</td>\n",
       "      <td>./train_code/problem019/problem019_63.cpp</td>\n",
       "      <td>#include &lt;iostream&gt;\\n\\nusing namespace std;\\n\\...</td>\n",
       "      <td>#include &lt;iostream&gt;\\n#include &lt;string&gt;\\nusing ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./train_code/problem107/problem107_486.cpp</td>\n",
       "      <td>./train_code/problem107/problem107_340.cpp</td>\n",
       "      <td>#include &lt;iostream&gt;\\n#include &lt;vector&gt;\\nusing ...</td>\n",
       "      <td>#include &lt;cstdio&gt;\\n#include &lt;cstdlib&gt;\\n#includ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./train_code/problem187/problem187_257.cpp</td>\n",
       "      <td>./train_code/problem403/problem403_135.cpp</td>\n",
       "      <td>#include &lt;bits/stdc++.h&gt;\\n#include &lt;unordered_...</td>\n",
       "      <td>#include &lt;bits/stdc++.h&gt;\\nusing namespace std;...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./train_code/problem173/problem173_490.cpp</td>\n",
       "      <td>./train_code/problem173/problem173_345.cpp</td>\n",
       "      <td>#include &lt;bits/stdc++.h&gt;\\ntypedef long long ll...</td>\n",
       "      <td>#include \"bits/stdc++.h\"\\n#define rep(i,n) for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   code1_path  \\\n",
       "0   ./train_code/problem393/problem393_19.cpp   \n",
       "1  ./train_code/problem019/problem019_210.cpp   \n",
       "2  ./train_code/problem107/problem107_486.cpp   \n",
       "3  ./train_code/problem187/problem187_257.cpp   \n",
       "4  ./train_code/problem173/problem173_490.cpp   \n",
       "\n",
       "                                   code2_path  \\\n",
       "0  ./train_code/problem033/problem033_439.cpp   \n",
       "1   ./train_code/problem019/problem019_63.cpp   \n",
       "2  ./train_code/problem107/problem107_340.cpp   \n",
       "3  ./train_code/problem403/problem403_135.cpp   \n",
       "4  ./train_code/problem173/problem173_345.cpp   \n",
       "\n",
       "                                               code1  \\\n",
       "0  #include <bits/stdc++.h>\\n\\nusing namespace st...   \n",
       "1  #include <iostream>\\n\\nusing namespace std;\\n\\...   \n",
       "2  #include <iostream>\\n#include <vector>\\nusing ...   \n",
       "3  #include <bits/stdc++.h>\\n#include <unordered_...   \n",
       "4  #include <bits/stdc++.h>\\ntypedef long long ll...   \n",
       "\n",
       "                                               code2  similar  \n",
       "0  #include <algorithm>\\n#include <bitset>\\n#incl...        0  \n",
       "1  #include <iostream>\\n#include <string>\\nusing ...        1  \n",
       "2  #include <cstdio>\\n#include <cstdlib>\\n#includ...        1  \n",
       "3  #include <bits/stdc++.h>\\nusing namespace std;...        0  \n",
       "4  #include \"bits/stdc++.h\"\\n#define rep(i,n) for...        1  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추가로 주어지는 Python Code 데이터들을 활용하여 새로운 Pair 쌍을 생성하여 더 많은 데이터로 학습할 수 있습니다.\n",
    "# 베이스라인에서는 이미 Pair 쌍으로 구축되어 주어지는 sample 데이터들로 검증을 진행합니다.\n",
    "val = pd.read_csv(\"./data/sample_train.csv\")\n",
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed61918b-271b-485b-9e6e-2a871ea24df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>code1</th>\n",
       "      <th>code2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000000</td>\n",
       "      <td>#include &lt;bits/stdc++.h&gt;\\nusing namespace std;...</td>\n",
       "      <td>#include &lt;bits/stdc++.h&gt;\\n#define rep(i, n) fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_000001</td>\n",
       "      <td>#include&lt;bits/stdc++.h&gt;\\n#define rep(i,n)for(i...</td>\n",
       "      <td>// //bitset操作\\n// #include &lt;iostream&gt;\\n// #inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_000002</td>\n",
       "      <td>#include &lt;bits/stdc++.h&gt;\\nusing namespace std;...</td>\n",
       "      <td>#include &lt;bits/stdc++.h&gt;\\n#include &lt;ext/pb_ds/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_000003</td>\n",
       "      <td>#include &lt;bits/stdc++.h&gt;\\nusing namespace std;...</td>\n",
       "      <td>#include &lt;bits/stdc++.h&gt;\\nusing namespace std;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_000004</td>\n",
       "      <td>#include&lt;bits/stdc++.h&gt;\\nusing namespace std;\\...</td>\n",
       "      <td>#include&lt;iostream&gt;\\n#include&lt;algorithm&gt;\\n#incl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pair_id                                              code1  \\\n",
       "0  TEST_000000  #include <bits/stdc++.h>\\nusing namespace std;...   \n",
       "1  TEST_000001  #include<bits/stdc++.h>\\n#define rep(i,n)for(i...   \n",
       "2  TEST_000002  #include <bits/stdc++.h>\\nusing namespace std;...   \n",
       "3  TEST_000003  #include <bits/stdc++.h>\\nusing namespace std;...   \n",
       "4  TEST_000004  #include<bits/stdc++.h>\\nusing namespace std;\\...   \n",
       "\n",
       "                                               code2  \n",
       "0  #include <bits/stdc++.h>\\n#define rep(i, n) fo...  \n",
       "1  // //bitset操作\\n// #include <iostream>\\n// #inc...  \n",
       "2  #include <bits/stdc++.h>\\n#include <ext/pb_ds/...  \n",
       "3  #include <bits/stdc++.h>\\nusing namespace std;...  \n",
       "4  #include<iostream>\\n#include<algorithm>\\n#incl...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20415d1-d28f-4e80-b338-7854505808ba",
   "metadata": {},
   "source": [
    "## Define Model (CountVectorizer+CosineSimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b02370cd-3cbc-433d-9dfe-d6f038a9167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel():\n",
    "    def __init__(self, threshold=0.5):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        self.threshold = threshold # 유사도 임계값\n",
    "        self.vocabulary = set()\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        return CountVectorizer(vocabulary=list(self.vocabulary))\n",
    "        \n",
    "    def fit(self, code, path):\n",
    "        try:\n",
    "            # 입력 받은 학습 코드로 부터 vectorizer를 fit 시킵니다.\n",
    "            temp_vectorizer = CountVectorizer()\n",
    "    \n",
    "            # 그 외 예외 처리\n",
    "            temp_vectorizer.fit(code)\n",
    "            # fit 호출 마다 vectorizer에 활용할 vocabulary 업데이트\n",
    "            self.vocabulary.update(temp_vectorizer.get_feature_names_out())\n",
    "            # fit 호출 마다 vectorizer 업데이트\n",
    "            self.vectorizer = self.get_vectorizer()\n",
    "        except Exception as e:\n",
    "            print(code, path)\n",
    "    \n",
    "    def predict_proba(self, code1, code2):\n",
    "        # 입력 받은 코드 쌍으로 부터 vectorizer를 통해 vector화 합니다.\n",
    "        code1_vecs = self.vectorizer.transform(code1)\n",
    "        code2_vecs = self.vectorizer.transform(code2)\n",
    "        \n",
    "        preds = []\n",
    "        # 각각의 코드 쌍(=벡터 쌍)으로부터 cosine-similarity를 구합니다.\n",
    "        for code1_vec, code2_vec in tqdm(zip(code1_vecs, code2_vecs)):\n",
    "            preds.append(cosine_similarity(code1_vec, code2_vec))\n",
    "        \n",
    "        preds = np.reshape(preds, len(preds))\n",
    "        print('Done.')\n",
    "        # 각 코드 쌍들의 유사도를 반환\n",
    "        return preds\n",
    "    \n",
    "    def predict(self, code1, code2):\n",
    "        preds = self.predict_proba(code1, code2)\n",
    "        # cosine-similarity (유사도)가 설정한 임계값(Threshold=0.5)보다 높다면 유사하다 : 1, 아니라면 유사하지 않다 : 0\n",
    "        preds = np.where(preds>self.threshold, 1, 0)\n",
    "        # 각 코드 쌍들의 유사도를 Threshold를 통해 유사함을 판별 (이진분류)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b97b86fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_semicolon(s):\n",
    "    \"\"\"\n",
    "    Replace all semicolon to \\n\n",
    "    \"\"\"\n",
    "    s = s.replace(';','\\n')\n",
    "    return s\n",
    "\n",
    "def remove_type(s):\n",
    "    s = s.replace('void', '')\n",
    "    s = s.replace('const', '')\n",
    "    return s\n",
    "\n",
    "def clean_comments(s):\n",
    "    \"\"\"\n",
    "    Remove sharp-leading comments from the beginning and any other place\n",
    "    \"\"\"\n",
    "    lines = s.split('\\n')\n",
    "    flag = False\n",
    "    clean = []\n",
    "    for line in lines:\n",
    "\n",
    "        # /* is procceeding\n",
    "        if flag:\n",
    "            if '*/' not in line:\n",
    "                continue\n",
    "            line = line[line.index('*/')+2:].rstrip()\n",
    "            flag = False\n",
    "\n",
    "        if line.lstrip().startswith('//'):\n",
    "            continue\n",
    "\n",
    "        if line.lstrip().startswith('/*'):\n",
    "            if '*/' not in line:\n",
    "                flag = True\n",
    "            continue\n",
    "\n",
    "        if '//' in line:\n",
    "            line = line[:line.index('//')].rstrip()\n",
    "\n",
    "        clean.append(line)\n",
    "    return '\\n'.join(clean)\n",
    "\n",
    "def clean_lex(s):\n",
    "    \"\"\"Remove `using namespace`\"\"\"\n",
    "    lines = s.split('\\n')\n",
    "    clean = []\n",
    "    for line in lines:\n",
    "        if 'using namespace' in line:\n",
    "            continue\n",
    "        clean.append(line)    \n",
    "    return '\\n'.join(clean)\n",
    "\n",
    "def clean_indents(s):\n",
    "    \"\"\"\n",
    "    Replace all types of spaces\n",
    "    \"\"\"\n",
    "    return ' '.join(s.split())\n",
    "\n",
    "def preproc(s):\n",
    "    \"\"\"Apply all cleaning functions\"\"\"\n",
    "    s = remove_semicolon(s)\n",
    "    s = remove_type(s)\n",
    "    s = clean_comments(s)\n",
    "    s = clean_lex(s)\n",
    "    s = clean_indents(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db119b87-c42f-49d2-af5e-e15ced996748",
   "metadata": {},
   "source": [
    "## Model(Vectorizer) Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1364eb8c-bd23-47ae-b3ab-8979266ab432",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_code_paths = glob.glob('./data/train_code/*/*.cpp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1e312037-5fd5-4701-8818-cea0a74e763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cpp_code(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a3c490ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#include<bits/stdc++.h> typedef long long ll typedef unsigned long long ull typedef vector<int> vi typedef vector<ll> vl typedef pair<int, int> pii typedef pair<ll, ll> pll typedef pair<ll, int> pli typedef pair<int, ll> pil typedef vector<pii> vii typedef vector<pil> vil typedef vector<pli> vli typedef vector<pll> vll #define ff first #define ss second #define pb push_back #define mp make_pair #define sz size() #define all(a) a.begin(), a.end() #define mem(a, b) memset(a, b, sizeof(a)) #define f0(i,n) for(ll i=0 i<(n) i++) #define f1(i,n) for(ll i=1 i<=(n) i++) #define f2(i,a,n) for(ll i=(a) i<=(n) i++) #define fr(i,n,a) for(ll i=(n) i>=(a) i--) #define rep(i,a,b,c) for(ll i=(a) i!=(b) i+=(c)) #define nl \"\\\\n\" int INF = 1e9 + 5 int MXN = 2e5 + 5 int MOD = 1e9 + 7 solve(){ int n cin >> n int a[n] f0(i, n) cin >> a[i] int mn = 0 ll tk = 1000, st = 0 f0(i, n-1){ if(a[i+1] > a[i]) continue else{ st = tk/a[mn] tk = tk-(st*a[mn])+(st*a[i]) mn = i+1 } } if(mn != n-1){ st = tk/a[mn] tk = tk-(st*a[mn])+(st*a[n-1]) } cout << tk << nl } int main(){ ll t t = 1 while(t--){ solve() } return 0 }'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preproc(s):\n",
    "    \"\"\"Apply all cleaning functions\"\"\"\n",
    "    s = remove_semicolon(s)\n",
    "    s = remove_type(s)\n",
    "    s = clean_comments(s)\n",
    "    s = clean_lex(s)\n",
    "    s = clean_indents(s)\n",
    "    return s\n",
    "preproc(read_cpp_code(\"./data/train_code/problem101/problem101_73.cpp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3f5fec7f-31f1-4a9b-ad69-f3de45ef78be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 선언\n",
    "model = BaselineModel(threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5151ae6c-8efc-4695-b372-40884c3b03e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [07:39<00:00, 544.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for path in tqdm(train_code_paths):\n",
    "    code = read_cpp_code(path)\n",
    "    preproc_code = preproc(code)\n",
    "    model.fit([preproc_code], path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0dc4f496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 사전을 파일로 저장\n",
    "with open('./result/vocabulary_v3_0.7.pkl', 'wb') as f:\n",
    "    pickle.dump(model.vocabulary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e923a5ba-91ad-485f-b7e3-61b9479a191e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63987"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a589465-dd3c-4a25-90ee-1ee60307e2f4",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "55fef54f-6eba-4890-9c39-c26f6c24f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(gt, preds):\n",
    "    return (gt == preds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b8f55fff-cb1a-4112-bca2-0702144df705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:21, 938.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_preds = model.predict(val['code1'].apply(preproc), val['code2'].apply(preproc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2074e2a5-62ad-4f0d-ac6c-b1b8d3949157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5472\n"
     ]
    }
   ],
   "source": [
    "print(get_accuracy(val['similar'].values, val_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93981f67-bb59-41b9-b1d7-67af59f7e393",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a8f82389-c08d-4b14-9b1e-d94d71ff214b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "450920it [07:54, 949.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 모델 추론\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcode1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreproc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcode2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreproc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 40\u001b[0m, in \u001b[0;36mBaselineModel.predict\u001b[0;34m(self, code1, code2)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, code1, code2):\n\u001b[0;32m---> 40\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# cosine-similarity (유사도)가 설정한 임계값(Threshold=0.5)보다 높다면 유사하다 : 1, 아니라면 유사하지 않다 : 0\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(preds\u001b[38;5;241m>\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[27], line 32\u001b[0m, in \u001b[0;36mBaselineModel.predict_proba\u001b[0;34m(self, code1, code2)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# 각각의 코드 쌍(=벡터 쌍)으로부터 cosine-similarity를 구합니다.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m code1_vec, code2_vec \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mzip\u001b[39m(code1_vecs, code2_vecs)):\n\u001b[0;32m---> 32\u001b[0m     preds\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode1_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode2_vec\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     34\u001b[0m preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(preds, \u001b[38;5;28mlen\u001b[39m(preds))\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1657\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1613\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1614\u001b[0m \n\u001b[1;32m   1615\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m-> 1657\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1659\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:172\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    165\u001b[0m         X,\n\u001b[1;32m    166\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 172\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:963\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array):\n\u001b[1;32m    962\u001b[0m     _ensure_no_complex_data(array)\n\u001b[0;32m--> 963\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_sparse_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;66;03m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;66;03m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;66;03m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;66;03m# of warnings context manager.\u001b[39;00m\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:631\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(sparse_container, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    626\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    627\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt check \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msparse_container\u001b[38;5;241m.\u001b[39mformat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sparse matrix for nan or inf.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    628\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    629\u001b[0m         )\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 631\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m            \u001b[49m\u001b[43msparse_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# TODO: Remove when the minimum version of SciPy supported is 1.12\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;66;03m# With SciPy sparse arrays, conversion from DIA format to COO, CSR, or BSR\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;66;03m# triggers the use of `np.int64` indices even if the data is such that it could\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;66;03m# algorithms support large indices, the following code downcasts to `np.int32`\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# indices when it's safe to do so.\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m changed_format:\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;66;03m# accept_sparse is specified to a specific format and a conversion occurred\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:121\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# error message.\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrstate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mover\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfirst_pass_isfinite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/numpy/core/_ufunc_config.py:436\u001b[0m, in \u001b[0;36merrstate.__exit__\u001b[0;34m(self, *exc_info)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mexc_info):\n\u001b[0;32m--> 436\u001b[0m     \u001b[43mseterr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moldstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _Unspecified:\n\u001b[1;32m    438\u001b[0m         seterrcall(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moldcall)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/numpy/core/_ufunc_config.py:128\u001b[0m, in \u001b[0;36mseterr\u001b[0;34m(all, divide, over, under, invalid)\u001b[0m\n\u001b[1;32m    122\u001b[0m maskvalue \u001b[38;5;241m=\u001b[39m ((_errdict[divide] \u001b[38;5;241m<<\u001b[39m SHIFT_DIVIDEBYZERO) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    123\u001b[0m              (_errdict[over] \u001b[38;5;241m<<\u001b[39m SHIFT_OVERFLOW) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    124\u001b[0m              (_errdict[under] \u001b[38;5;241m<<\u001b[39m SHIFT_UNDERFLOW) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    125\u001b[0m              (_errdict[invalid] \u001b[38;5;241m<<\u001b[39m SHIFT_INVALID))\n\u001b[1;32m    127\u001b[0m pyvals[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m maskvalue\n\u001b[0;32m--> 128\u001b[0m umath\u001b[38;5;241m.\u001b[39mseterrobj(pyvals)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m old\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 추론\n",
    "preds = model.predict(test['code1'].apply(preproc), test['code2'].apply(preproc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e884cd-f9a8-4274-9a07-e1f4443ca51c",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9666a4d-922a-4eeb-a58b-db4ee3950f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission['similar'] = preds\n",
    "submission.to_csv('./result/preproc_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
